{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.extract import *\n",
    "from src.preprocess import *\n",
    "\n",
    "WORD_LEN = 12\n",
    "PADDING_CHAR = '^' # Use ^ since it's rarely used in normal word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54520 ['^^^^^^^^^^^^', ' transfer ()', '40507^^^^^^^', '&#x1f486;&#x', 'richEditingE', 'Failed to pa', '3e2414d82acc', '&#x1f468;&#x', 'ADAUSDTM^^^^', '&#x1f1ec;&#x']\n"
     ]
    }
   ],
   "source": [
    "normal_words = get_words_from_files('data\\\\train\\\\WordPress-master\\\\*\\\\*.php')\n",
    "normal_words = normal_words.union(get_words_from_files('data\\\\train\\\\ccxt-master\\\\*\\\\*.php'))\n",
    "prep_normal_words = preprocess_words(normal_words, word_len=WORD_LEN, padding_char=PADDING_CHAR)\n",
    "print(len(prep_normal_words), prep_normal_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39984 ['1qaz2wsx^^^^', '306187mn^^^^', 'rados1^^^^^^', 'newyork911^^', 'abc123^^^^^^', 'taqiyudin100', 'wjr5443^^^^^', 'nana0428^^^^', '1992jp^^^^^^', 'bahamut24rit']\n"
     ]
    }
   ],
   "source": [
    "passwords = open('data/train/000webhost.txt', 'rb').read().decode().split('\\n')\n",
    "user_pass = passwords[:40000]\n",
    "prep_user_pass = preprocess_words(user_pass, word_len=WORD_LEN, padding_char=PADDING_CHAR)\n",
    "print(len(prep_user_pass), prep_user_pass[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [encode_str(word), 0]\n",
    "    for word in prep_normal_words\n",
    "] + [\n",
    "    [encode_str(word), 1]\n",
    "    for word in prep_user_pass\n",
    "]\n",
    "\n",
    "random.shuffle(data)\n",
    "X = np.asarray([row[0] for row in data])\n",
    "y = np.asarray([row[1] for row in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(30, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(10),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[keras.metrics.Recall()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "222/222 [==============================] - 8s 19ms/step - loss: 0.5004 - recall: 0.5586 - val_loss: 0.3771 - val_recall: 0.7217\n",
      "Epoch 2/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.3457 - recall: 0.7803 - val_loss: 0.3100 - val_recall: 0.7879\n",
      "Epoch 3/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.2998 - recall: 0.8253 - val_loss: 0.2710 - val_recall: 0.8326\n",
      "Epoch 4/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.2655 - recall: 0.8509 - val_loss: 0.2381 - val_recall: 0.8750\n",
      "Epoch 5/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.2483 - recall: 0.8603 - val_loss: 0.2410 - val_recall: 0.8427\n",
      "Epoch 6/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.2385 - recall: 0.8654 - val_loss: 0.2286 - val_recall: 0.8965\n",
      "Epoch 7/100\n",
      "222/222 [==============================] - 2s 11ms/step - loss: 0.2312 - recall: 0.8705 - val_loss: 0.2218 - val_recall: 0.9082\n",
      "Epoch 8/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.2204 - recall: 0.8780 - val_loss: 0.2116 - val_recall: 0.9006\n",
      "Epoch 9/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.2191 - recall: 0.8777 - val_loss: 0.2018 - val_recall: 0.8996\n",
      "Epoch 10/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.2105 - recall: 0.8843 - val_loss: 0.2070 - val_recall: 0.9056\n",
      "Epoch 11/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.2106 - recall: 0.8855 - val_loss: 0.2002 - val_recall: 0.8854\n",
      "Epoch 12/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.2038 - recall: 0.8904 - val_loss: 0.2046 - val_recall: 0.8755\n",
      "Epoch 13/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1968 - recall: 0.8969 - val_loss: 0.1955 - val_recall: 0.9168\n",
      "Epoch 14/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1960 - recall: 0.8989 - val_loss: 0.1930 - val_recall: 0.8906\n",
      "Epoch 15/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1878 - recall: 0.9036 - val_loss: 0.1828 - val_recall: 0.9211\n",
      "Epoch 16/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1895 - recall: 0.9012 - val_loss: 0.1845 - val_recall: 0.8906\n",
      "Epoch 17/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1815 - recall: 0.9066 - val_loss: 0.1828 - val_recall: 0.9086\n",
      "Epoch 18/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1836 - recall: 0.9044 - val_loss: 0.1812 - val_recall: 0.9028\n",
      "Epoch 19/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1767 - recall: 0.9100 - val_loss: 0.1811 - val_recall: 0.9293\n",
      "Epoch 20/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1733 - recall: 0.9113 - val_loss: 0.1787 - val_recall: 0.9054\n",
      "Epoch 21/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1741 - recall: 0.9097 - val_loss: 0.1721 - val_recall: 0.9267\n",
      "Epoch 22/100\n",
      "222/222 [==============================] - 3s 14ms/step - loss: 0.1715 - recall: 0.9133 - val_loss: 0.1708 - val_recall: 0.9160\n",
      "Epoch 23/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1673 - recall: 0.9149 - val_loss: 0.1746 - val_recall: 0.9292\n",
      "Epoch 24/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1680 - recall: 0.9137 - val_loss: 0.1673 - val_recall: 0.9120\n",
      "Epoch 25/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1618 - recall: 0.9167 - val_loss: 0.1623 - val_recall: 0.9181\n",
      "Epoch 26/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1617 - recall: 0.9172 - val_loss: 0.1615 - val_recall: 0.9209\n",
      "Epoch 27/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1611 - recall: 0.9184 - val_loss: 0.1592 - val_recall: 0.9221\n",
      "Epoch 28/100\n",
      "222/222 [==============================] - 2s 11ms/step - loss: 0.1591 - recall: 0.9182 - val_loss: 0.1555 - val_recall: 0.9219\n",
      "Epoch 29/100\n",
      "222/222 [==============================] - 3s 12ms/step - loss: 0.1570 - recall: 0.9201 - val_loss: 0.1556 - val_recall: 0.9206\n",
      "Epoch 30/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1582 - recall: 0.9190 - val_loss: 0.1553 - val_recall: 0.9223\n",
      "Epoch 31/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1545 - recall: 0.9216 - val_loss: 0.1649 - val_recall: 0.9196\n",
      "Epoch 32/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1541 - recall: 0.9201 - val_loss: 0.1548 - val_recall: 0.9249\n",
      "Epoch 33/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1527 - recall: 0.9228 - val_loss: 0.1544 - val_recall: 0.9277\n",
      "Epoch 34/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1526 - recall: 0.9218 - val_loss: 0.1520 - val_recall: 0.9227\n",
      "Epoch 35/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1497 - recall: 0.9242 - val_loss: 0.1505 - val_recall: 0.9277\n",
      "Epoch 36/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1485 - recall: 0.9251 - val_loss: 0.1566 - val_recall: 0.9251\n",
      "Epoch 37/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1500 - recall: 0.9232 - val_loss: 0.1540 - val_recall: 0.9318\n",
      "Epoch 38/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1460 - recall: 0.9258 - val_loss: 0.1468 - val_recall: 0.9244\n",
      "Epoch 39/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1465 - recall: 0.9249 - val_loss: 0.1549 - val_recall: 0.9269\n",
      "Epoch 40/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1446 - recall: 0.9265 - val_loss: 0.1606 - val_recall: 0.9198\n",
      "Epoch 41/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1426 - recall: 0.9278 - val_loss: 0.1484 - val_recall: 0.9226\n",
      "Epoch 42/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1437 - recall: 0.9269 - val_loss: 0.1449 - val_recall: 0.9247\n",
      "Epoch 43/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1428 - recall: 0.9276 - val_loss: 0.1483 - val_recall: 0.9280\n",
      "Epoch 44/100\n",
      "222/222 [==============================] - 3s 12ms/step - loss: 0.1422 - recall: 0.9278 - val_loss: 0.1465 - val_recall: 0.9198\n",
      "Epoch 45/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1413 - recall: 0.9290 - val_loss: 0.1489 - val_recall: 0.9313\n",
      "Epoch 46/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1427 - recall: 0.9279 - val_loss: 0.1439 - val_recall: 0.9265\n",
      "Epoch 47/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1396 - recall: 0.9297 - val_loss: 0.1434 - val_recall: 0.9285\n",
      "Epoch 48/100\n",
      "222/222 [==============================] - 3s 13ms/step - loss: 0.1396 - recall: 0.9279 - val_loss: 0.1422 - val_recall: 0.9323\n",
      "Epoch 49/100\n",
      "222/222 [==============================] - 3s 14ms/step - loss: 0.1372 - recall: 0.9316 - val_loss: 0.1689 - val_recall: 0.8881\n",
      "Epoch 50/100\n",
      "222/222 [==============================] - 4s 16ms/step - loss: 0.1400 - recall: 0.9290 - val_loss: 0.1480 - val_recall: 0.9213\n",
      "Epoch 51/100\n",
      "222/222 [==============================] - 3s 12ms/step - loss: 0.1359 - recall: 0.9320 - val_loss: 0.1499 - val_recall: 0.9270\n",
      "Epoch 52/100\n",
      "222/222 [==============================] - 2s 11ms/step - loss: 0.1350 - recall: 0.9318 - val_loss: 0.1411 - val_recall: 0.9297\n",
      "Epoch 53/100\n",
      "222/222 [==============================] - 2s 11ms/step - loss: 0.1362 - recall: 0.9312 - val_loss: 0.1463 - val_recall: 0.9226\n",
      "Epoch 54/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1339 - recall: 0.9323 - val_loss: 0.1406 - val_recall: 0.9297\n",
      "Epoch 55/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1313 - recall: 0.9324 - val_loss: 0.1375 - val_recall: 0.9287\n",
      "Epoch 56/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1330 - recall: 0.9320 - val_loss: 0.1449 - val_recall: 0.9234\n",
      "Epoch 57/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1307 - recall: 0.9340 - val_loss: 0.1407 - val_recall: 0.9232\n",
      "Epoch 58/100\n",
      "222/222 [==============================] - 2s 11ms/step - loss: 0.1286 - recall: 0.9345 - val_loss: 0.1401 - val_recall: 0.9293\n",
      "Epoch 59/100\n",
      "222/222 [==============================] - 2s 11ms/step - loss: 0.1326 - recall: 0.9327 - val_loss: 0.1479 - val_recall: 0.9335\n",
      "Epoch 60/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1288 - recall: 0.9356 - val_loss: 0.1418 - val_recall: 0.9315\n",
      "Epoch 61/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1337 - recall: 0.9325 - val_loss: 0.1423 - val_recall: 0.9211\n",
      "Epoch 62/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1294 - recall: 0.9342 - val_loss: 0.1391 - val_recall: 0.9251\n",
      "Epoch 63/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1282 - recall: 0.9353 - val_loss: 0.1359 - val_recall: 0.9371\n",
      "Epoch 64/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1273 - recall: 0.9355 - val_loss: 0.1400 - val_recall: 0.9282\n",
      "Epoch 65/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1286 - recall: 0.9342 - val_loss: 0.1320 - val_recall: 0.9298\n",
      "Epoch 66/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1263 - recall: 0.9370 - val_loss: 0.1427 - val_recall: 0.9227\n",
      "Epoch 67/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1253 - recall: 0.9365 - val_loss: 0.1350 - val_recall: 0.9221\n",
      "Epoch 68/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1240 - recall: 0.9380 - val_loss: 0.1372 - val_recall: 0.9252\n",
      "Epoch 69/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1237 - recall: 0.9375 - val_loss: 0.1405 - val_recall: 0.9345\n",
      "Epoch 70/100\n",
      "222/222 [==============================] - 2s 11ms/step - loss: 0.1260 - recall: 0.9355 - val_loss: 0.1339 - val_recall: 0.9247\n",
      "Epoch 71/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1256 - recall: 0.9366 - val_loss: 0.1319 - val_recall: 0.9351\n",
      "Epoch 72/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1245 - recall: 0.9369 - val_loss: 0.1449 - val_recall: 0.9190\n",
      "Epoch 73/100\n",
      "222/222 [==============================] - 3s 11ms/step - loss: 0.1234 - recall: 0.9374 - val_loss: 0.1403 - val_recall: 0.9323\n",
      "Epoch 74/100\n",
      "222/222 [==============================] - 3s 12ms/step - loss: 0.1244 - recall: 0.9366 - val_loss: 0.1406 - val_recall: 0.9426\n",
      "Epoch 75/100\n",
      "222/222 [==============================] - 2s 11ms/step - loss: 0.1251 - recall: 0.9369 - val_loss: 0.1333 - val_recall: 0.9368\n",
      "Epoch 76/100\n",
      "222/222 [==============================] - 2s 11ms/step - loss: 0.1201 - recall: 0.9385 - val_loss: 0.1374 - val_recall: 0.9406\n",
      "Epoch 77/100\n",
      "222/222 [==============================] - 2s 11ms/step - loss: 0.1216 - recall: 0.9379 - val_loss: 0.1316 - val_recall: 0.9336\n",
      "Epoch 78/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1188 - recall: 0.9391 - val_loss: 0.1353 - val_recall: 0.9280\n",
      "Epoch 79/100\n",
      "222/222 [==============================] - 3s 13ms/step - loss: 0.1200 - recall: 0.9384 - val_loss: 0.1325 - val_recall: 0.9302\n",
      "Epoch 80/100\n",
      "222/222 [==============================] - 3s 11ms/step - loss: 0.1194 - recall: 0.9400 - val_loss: 0.1401 - val_recall: 0.9260\n",
      "Epoch 81/100\n",
      "222/222 [==============================] - 3s 12ms/step - loss: 0.1194 - recall: 0.9394 - val_loss: 0.1292 - val_recall: 0.9384\n",
      "Epoch 82/100\n",
      "222/222 [==============================] - 4s 16ms/step - loss: 0.1177 - recall: 0.9404 - val_loss: 0.1280 - val_recall: 0.9323\n",
      "Epoch 83/100\n",
      "222/222 [==============================] - 3s 12ms/step - loss: 0.1159 - recall: 0.9422 - val_loss: 0.1286 - val_recall: 0.9274\n",
      "Epoch 84/100\n",
      "222/222 [==============================] - 3s 14ms/step - loss: 0.1204 - recall: 0.9389 - val_loss: 0.1279 - val_recall: 0.9310\n",
      "Epoch 85/100\n",
      "222/222 [==============================] - 3s 12ms/step - loss: 0.1170 - recall: 0.9410 - val_loss: 0.1381 - val_recall: 0.9295\n",
      "Epoch 86/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1165 - recall: 0.9417 - val_loss: 0.1330 - val_recall: 0.9284\n",
      "Epoch 87/100\n",
      "222/222 [==============================] - 3s 12ms/step - loss: 0.1160 - recall: 0.9414 - val_loss: 0.1417 - val_recall: 0.9128\n",
      "Epoch 88/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1177 - recall: 0.9394 - val_loss: 0.1280 - val_recall: 0.9305\n",
      "Epoch 89/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1145 - recall: 0.9422 - val_loss: 0.1375 - val_recall: 0.9317\n",
      "Epoch 90/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1161 - recall: 0.9405 - val_loss: 0.1401 - val_recall: 0.9376\n",
      "Epoch 91/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1148 - recall: 0.9408 - val_loss: 0.1261 - val_recall: 0.9341\n",
      "Epoch 92/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1141 - recall: 0.9414 - val_loss: 0.1374 - val_recall: 0.9293\n",
      "Epoch 93/100\n",
      "222/222 [==============================] - 2s 11ms/step - loss: 0.1144 - recall: 0.9424 - val_loss: 0.1257 - val_recall: 0.9417\n",
      "Epoch 94/100\n",
      "222/222 [==============================] - 2s 9ms/step - loss: 0.1145 - recall: 0.9414 - val_loss: 0.1347 - val_recall: 0.9355\n",
      "Epoch 95/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1153 - recall: 0.9411 - val_loss: 0.1285 - val_recall: 0.9264\n",
      "Epoch 96/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1118 - recall: 0.9424 - val_loss: 0.1300 - val_recall: 0.9340\n",
      "Epoch 97/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1160 - recall: 0.9406 - val_loss: 0.1250 - val_recall: 0.9386\n",
      "Epoch 98/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1110 - recall: 0.9448 - val_loss: 0.1285 - val_recall: 0.9323\n",
      "Epoch 99/100\n",
      "222/222 [==============================] - 2s 10ms/step - loss: 0.1123 - recall: 0.9426 - val_loss: 0.1437 - val_recall: 0.9303\n",
      "Epoch 100/100\n",
      "222/222 [==============================] - 2s 11ms/step - loss: 0.1122 - recall: 0.9427 - val_loss: 0.1248 - val_recall: 0.9358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x205561e0b50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739/739 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9682656053623796, 0.9356340451371319)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "y_pred = model.predict(X_test) > 0.5\n",
    "(\n",
    "    precision_score(y_test, y_pred),\n",
    "    recall_score(y_test, y_pred)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"rnn_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04635d289a519a1410467dd0afb0db42f9184808881ca68b2eb5a687a20a5a94"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
